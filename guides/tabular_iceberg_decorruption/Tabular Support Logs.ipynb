{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbc2571",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"conf\": {\n",
    "    \"spark.app.name\": \"Tabular Support Logs Monitoring\",\n",
    "        \n",
    "        \n",
    "    \"master\": \"yarn\",\n",
    "    \"deployMode\": \"client\",\n",
    "    \"executor.instances\": \"1\",\n",
    "    \"executor.memory\": \"1G\",\n",
    "    \"executor.cores\": \"1\",\n",
    "    \"driver.memory\": \"1G\",\n",
    "    \"driver.cores\": \"1\",\n",
    "    \"dynamicAllocation.enabled\": \"false\",\n",
    "      \n",
    "    \"spark.dynamicAllocation.minExecutors\": \"1\",    \n",
    "    \n",
    "    \"spark.sql.catalog.my_warehouse\": \"org.apache.iceberg.spark.SparkCatalog\",\n",
    "    \"spark.sql.catalog.my_warehouse.catalog-impl\": \"org.apache.iceberg.rest.RESTCatalog\",\n",
    "    \"spark.sql.catalog.my_warehouse.credential\": \"t-asdf:asdf-asdf\",\n",
    "    \"spark.sql.catalog.my_warehouse.region\": \"us-east-1\",\n",
    "    \"spark.sql.catalog.my_warehouse.uri\": \"https://api.tabular.io/ws/\",\n",
    "    \"spark.sql.catalog.my_warehouse.warehouse\": \"my_warehouse\",\n",
    "      \n",
    "    \"spark.sql.defaultCatalog\": \"my_warehouse\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c70e78",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def monitor():\n",
    "    # Query to get the latest batch ID and compute the job duration\n",
    "    result = spark.sql(\"\"\"\n",
    "        with latest_batch as (\n",
    "            select \n",
    "                batch_id,\n",
    "                max(event_ts) as last_message_received_at,\n",
    "                min(event_ts) as first_message_received_at\n",
    "            from\n",
    "                tabular_support.logs\n",
    "            group by \n",
    "                batch_id\n",
    "            order by \n",
    "                last_message_received_at desc\n",
    "            limit 1\n",
    "        )\n",
    "        select \n",
    "            batch_id,\n",
    "            cast(last_message_received_at as timestamp) as last_message_received_at,\n",
    "            cast(first_message_received_at as timestamp) as first_message_received_at\n",
    "        from \n",
    "            latest_batch\n",
    "    \"\"\").collect()\n",
    "\n",
    "    if result:\n",
    "        latest_batch = result[0]\n",
    "        batch_id = latest_batch[0]\n",
    "        last_message_received_at = latest_batch[1]\n",
    "        first_message_received_at = latest_batch[2]\n",
    "\n",
    "        duration = last_message_received_at - first_message_received_at\n",
    "        hours, remainder = divmod(duration.total_seconds(), 3600)\n",
    "        minutes, seconds = divmod(remainder, 60)\n",
    "\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Batch ID:   {batch_id}\")\n",
    "        print(f\"Start Time: {first_message_received_at}\")\n",
    "        print(f\"End Time:   {last_message_received_at}\")\n",
    "        print(f\"Duration:   {int(hours)}h {int(minutes)}m {int(seconds)}s\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "        # Query to get the messages for the latest batch\n",
    "        logs = spark.sql(f\"\"\"\n",
    "            select \n",
    "                event_message\n",
    "            from \n",
    "                tabular_support.logs\n",
    "            where \n",
    "                batch_id = '{batch_id}'\n",
    "            order by \n",
    "                event_ts\n",
    "        \"\"\")\n",
    "\n",
    "        for row in logs.collect():\n",
    "            print(f\"{row[0]}\")\n",
    "            \n",
    "        print(\"=\"*80)\n",
    "        \n",
    "    else:\n",
    "        print(\"No batches found.\")\n",
    "\n",
    "monitor()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
