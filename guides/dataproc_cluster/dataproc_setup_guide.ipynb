{"cells":[{"cell_type":"markdown","id":"c428fcc0-ed19-4573-9ca2-48df5137e49d","metadata":{},"source":["# Tabular - GCP Dataproc Guide\n","This script shows you how to configure a fresh dataproc cluster for use with [Tabular](tabular.io).\n","\n","**NOTE**: You'll need a Tabular credential for this. Log in to your Tabular account and create a service credential. You'll figure it out üåû \n","\n","The steps are:\n","- install spark dependencies\n","- register the Tabular Iceberg REST Catalog with spark\n","- write some sample queries!\n","\n","üö®‚ö†Ô∏è - If you need ANY help, please reach out to support@tabular.io\n","\n","\n","## Before we begin, provide your inputs below."]},{"cell_type":"code","execution_count":null,"id":"33cc3623-6a18-4155-9e51-29772481f799","metadata":{},"outputs":[],"source":["# üëá replace this with your own credential and your tabular warehouse name\n","tabular_credential = 't-123:456'\n","warehouse_name = 'rpw_gcp'"]},{"cell_type":"markdown","id":"01517416-215f-4b14-8224-6d79fd987ee3","metadata":{},"source":["## 1 - Install dependencies\n","Nothing too tricky here. \n","- Spark needs a JAR to help it talk with Apache Iceberg.\n","- Iceberg needs a JAR to help it talk with GCS buckets\n","\n","### Spark Iceberg Runtime\n","I like to go to the [Apache Iceberg site](https://iceberg.apache.org/releases/) to grab a release that matches the version of Spark I'm using.\n","- For this notebook, I'm using Spark 3.3 with Scala 2.12. \n","- So I grabbed the [1.4.3 Spark 3.3_2.12 runtime Jar](https://search.maven.org/remotecontent?filepath=org/apache/iceberg/iceberg-spark-runtime-3.3_2.12/1.4.3/iceberg-spark-runtime-3.3_2.12-1.4.3.jar) release\n","- Copy the link you want and place it in the first entry in the `url` list.\n","\n","### Iceberg GCP Bundle\n","You can get this again at the [Apache Iceberg site](https://iceberg.apache.org/releases/)\n","- I always just grab the latest version of this, regardless of Spark version\n","- I'm using this one [1.4.3 gcp-bundle Jar](https://search.maven.org/remotecontent?filepath=org/apache/iceberg/iceberg-gcp-bundle/1.4.3/iceberg-gcp-bundle-1.4.3.jar) release\n","- Copy the link you want and place it in the second entry of the `url` list."]},{"cell_type":"code","execution_count":1,"id":"e6334211-814c-4533-b8c6-dbd9a568a0f9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully installed iceberg-spark-runtime-3.3_2.12-1.4.3.jar into /usr/lib/spark/jars\n","Successfully installed iceberg-gcp-bundle-1.4.3.jar into /usr/lib/spark/jars\n","\n","\n","Spark package sring: \"org.apache.iceberg:iceberg-spark-runtime-3.3_2.12-1.4.3,org.apache.iceberg:iceberg-gcp-bundle-1.4.3\"\n"]}],"source":["# üëá replace these if you have a different spark env\n","spark_iceberg_runtime_url = \"https://search.maven.org/remotecontent?filepath=org/apache/iceberg/iceberg-spark-runtime-3.3_2.12/1.4.3/iceberg-spark-runtime-3.3_2.12-1.4.3.jar\"\n","iceberg_gcp_bundle_url = \"https://search.maven.org/remotecontent?filepath=org/apache/iceberg/iceberg-gcp-bundle/1.4.3/iceberg-gcp-bundle-1.4.3.jar\"\n","\n","\n","import requests\n","\n","# Define the paths where the jars should be stored\n","urls = [\n","  spark_iceberg_runtime_url,\n","  iceberg_gcp_bundle_url,\n","]\n","deps_folder = '/usr/lib/spark/jars'\n","filenames = [url.split('/')[-1] for url in urls]\n","\n","# install each jar\n","for url, filename in zip(urls, filenames):\n","    r = requests.get(url)\n","    path = f'{deps_folder}/{filename}'\n","    with open(path, 'wb') as f:\n","        f.write(r.content)\n","        print(f'Successfully installed {filename} into {deps_folder}')\n","\n","        \n","# Now build a pkg string telling spark what deps to load\n","pkgs = [f'org.apache.iceberg:{filename.replace(\".jar\", \"\")}' for filename in filenames]\n","pkgs_str = ','.join(pkgs)\n","print(f'\\n\\nSpark package sring: \"{pkgs_str}\"')"]},{"cell_type":"markdown","id":"34895875-cf44-4619-8e79-18ab72248941","metadata":{},"source":["## 2 - Connect Spark to Tabular üí™\n","Let's get an old-fashioned python Spark session cooking and connect to Tabular."]},{"cell_type":"code","execution_count":2,"id":"9a104f83-f6a3-4169-abf6-06f017d25e50","metadata":{"tags":[]},"outputs":[{"name":"stderr","output_type":"stream","text":["24/01/20 17:02:36 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","spark = (\n","  SparkSession.builder\n","    .appName(\"Iceberg\")\n","    .config(\"spark.jars.packages\", pkgs_str)\n","    .config(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n","    .config(f\"spark.sql.catalog.{warehouse_name}\", \"org.apache.iceberg.spark.SparkCatalog\")\n","    .config(f\"spark.sql.catalog.{warehouse_name}.catalog-impl\", \"org.apache.iceberg.rest.RESTCatalog\")\n","    .config(f\"spark.sql.catalog.{warehouse_name}.uri\", \"https://api.tabular.io/ws\")\n","    .config(f\"spark.sql.catalog.{warehouse_name}.credential\", tabular_credential)\n","    .config(f\"spark.sql.catalog.{warehouse_name}.warehouse\", warehouse_name)\n","    .config(\"spark.sql.defaultCatalog\", warehouse_name)\n","    .getOrCreate()\n",")"]},{"cell_type":"markdown","id":"d234b912-7eeb-4c72-b9e5-34f067bab690","metadata":{},"source":["## 3 - Run sample queries to validate your connection"]},{"cell_type":"code","execution_count":4,"id":"3cb226ff-c2b4-4e72-9943-59b0d6b12d3a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+\n","|catalog|\n","+-------+\n","|rpw_gcp|\n","+-------+\n","\n","+---+\n","| ID|\n","+---+\n","|  1|\n","+---+\n","\n"]}],"source":["spark.sql(f'SHOW CATALOGS;').show()\n","\n","spark.sql(f'CREATE DATABASE IF NOT EXISTS {warehouse_name}.DATAPROC_INIT;')\n","spark.sql(f'CREATE TABLE IF NOT EXISTS {warehouse_name}.DATAPROC_INIT.HELLO_WORLD AS (SELECT 1 AS ID);')\n","\n","\n","spark.sql(\n","    f'SELECT * FROM {warehouse_name}.DATAPROC_INIT.HELLO_WORLD;'\n",").show()"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":5}
